#################################################################################################################################################################################################
######################################################################### RUN SETTINGS FOR DSST REGRESSION DATASET ######################################################################
#################################################################################################################################################################################################

# Grid search parameters - all combinations will be tested
grid_search:
  dsst_custom:
    # dropout_rates: [0.3, 0.5, 0.7]
    # weight_decays: [0.001, 0.01, 0.1]
    # layers_nums: [2]
    dropout_rates: [0.5]
    weight_decays: [0.1]
    # weight_decays: [0.01]
    layers_nums: [3]
  gf_custom:
    # dropout_rates: [0.3, 0.5, 0.7]
    # weight_decays: [0.001, 0.01, 0.1]
    # layers_nums: [2]
    dropout_rates: [0.5]
    weight_decays: [0.1]
    # weight_decays: [0.01]
    layers_nums: [3]

lrs:
  dsst_custom:
    - 0.001
  gf_custom:
    - 0.001

epochs:
  dsst_custom:
    - 200
  gf_custom:
    - 200

# Number of runs for statistical significance
runs:
  dsst_custom:
    - 3
  gf_custom:
    - 3

# Early stopping configurations
early_stopping:
  dsst_custom:
    - enabled: true
      patience: 25
      min_delta: 0.0001
      restore_best_weights: true
      verbose: true
      monitor: "r2"
  gf_custom:
    - enabled: true
      patience: 25
      min_delta: 0.0001
      restore_best_weights: true
      verbose: true
      monitor: "r2"

# Learning rate scheduler configurations
schedulers:
  dsst_custom:
    - scheduler: "warmup_cosine"
      scheduler_params:
        num_warmup_steps: 20
        num_training_steps: 200
        num_cycles: 0.5
        last_epoch: -1
  gf_custom:
    - scheduler: "warmup_cosine"
      scheduler_params:
        num_warmup_steps: 20
        num_training_steps: 200
        num_cycles: 0.5
        last_epoch: -1

    # CosineAnnealingLR: Cosine annealing
    # - scheduler: "cosine"
    #   scheduler_params:
    #     T_max: 254
    #     eta_min: 0.000001

    # StepLR: Decay LR by gamma every step_size epochs
    # - scheduler: "step"
    #   scheduler_params:
    #     step_size: 25
    #     gamma: 0.5
    
    # MultiStepLR: Decay LR at specific milestones
    # - scheduler: "multistep"
    #   scheduler_params:
    #     milestones: [150, 300]
    #     gamma: 0.1
    
    # ExponentialLR: Decay LR exponentially
    # - scheduler: "exponential"
    #   scheduler_params:
    #     gamma: 0.95
    
    # ReduceLROnPlateau: Reduce when metric plateaus
    # - scheduler: "plateau"
    #   scheduler_params:
    #     factor: 0.5
    #     patience: 10
    #     min_lr: 0.000001