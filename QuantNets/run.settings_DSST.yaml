#################################################################################################################################################################################################
######################################################################### RUN SETTINGS FOR DSST REGRESSION DATASET ######################################################################
#################################################################################################################################################################################################

# Learning rates - regression typically needs different rates than classification
lrs:
  dsst_custom:
    - 0.001
  gf_custom:
    - 0.001

# Epochs - regression may need more epochs to converge
epochs:
  dsst_custom:
    - 500
  gf_custom:
    - 257

# Number of runs for statistical significance
runs:
  dsst_custom:
    - 3
  gf_custom:
    - 3

# Learning rate scheduler configurations
schedulers:
  dsst_custom:
    # StepLR: Decay LR by gamma every step_size epochs
    - scheduler: "step"
      scheduler_params:
        step_size: 50
        gamma: 0.5
  gf_custom:
    # Warmup Cosine: Linear warmup followed by cosine decay
    - scheduler: "warmup_cosine"
      scheduler_params:
        num_warmup_steps: 25
        num_training_steps: 257
        num_cycles: 0.5
        last_epoch: -1

    # CosineAnnealingLR: Cosine annealing
    # - scheduler: "cosine"
    #   scheduler_params:
    #     T_max: 254
    #     eta_min: 0.000001

    # StepLR: Decay LR by gamma every step_size epochs
    # - scheduler: "step"
    #   scheduler_params:
    #     step_size: 25
    #     gamma: 0.5
    
    # MultiStepLR: Decay LR at specific milestones
    # - scheduler: "multistep"
    #   scheduler_params:
    #     milestones: [150, 300]
    #     gamma: 0.1
    
    # ExponentialLR: Decay LR exponentially
    # - scheduler: "exponential"
    #   scheduler_params:
    #     gamma: 0.95
    
    # ReduceLROnPlateau: Reduce when metric plateaus
    # - scheduler: "plateau"
    #   scheduler_params:
    #     factor: 0.5
    #     patience: 10
    #     min_lr: 0.000001