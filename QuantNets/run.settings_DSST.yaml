#################################################################################################################################################################################################
######################################################################### RUN SETTINGS FOR DSST REGRESSION DATASET ######################################################################
#################################################################################################################################################################################################

# Grid search parameters - all combinations will be tested
grid_search:
  gf_custom:
    # dropout_rates: [0.1, 0.3, 0.5, 0.7]
    # weight_decays: [0.0001, 0.001, 0.01, 0.1]
    # layers_nums: [2, 3, 4]
    dropout_rates: [0.5]
    weight_decays: [0.1]
    layers_nums: [2, 3, 4]
# Learning rates - regression typically needs different rates than classification
lrs:
  dsst_custom:
    - 0.001
  gf_custom:
    - 0.01

# Epochs - regression may need more epochs to converge
epochs:
  dsst_custom:
    - 500
  gf_custom:
    - 200

# Number of runs for statistical significance
runs:
  dsst_custom:
    - 3
  gf_custom:
    - 3

# Early stopping configurations
early_stopping:
  dsst_custom:
    - enabled: true
      patience: 30
      min_delta: 0.001
      restore_best_weights: true
      verbose: true
      monitor: "r2"  # Monitor R² instead of loss
  gf_custom:
    - enabled: true
      patience: 20
      min_delta: 0.001
      restore_best_weights: true
      verbose: true
      monitor: "r2"  # Monitor R² instead of loss

# Learning rate scheduler configurations
schedulers:
  dsst_custom:
    # StepLR: Decay LR by gamma every step_size epochs
    - scheduler: "step"
      scheduler_params:
        step_size: 50
        gamma: 0.5
  gf_custom:
    # Warmup Cosine: Linear warmup followed by cosine decay
    - scheduler: "warmup_cosine"
      scheduler_params:
        num_warmup_steps: 20
        num_training_steps: 200
        num_cycles: 0.5
        last_epoch: -1

    # CosineAnnealingLR: Cosine annealing
    # - scheduler: "cosine"
    #   scheduler_params:
    #     T_max: 254
    #     eta_min: 0.000001

    # StepLR: Decay LR by gamma every step_size epochs
    # - scheduler: "step"
    #   scheduler_params:
    #     step_size: 25
    #     gamma: 0.5
    
    # MultiStepLR: Decay LR at specific milestones
    # - scheduler: "multistep"
    #   scheduler_params:
    #     milestones: [150, 300]
    #     gamma: 0.1
    
    # ExponentialLR: Decay LR exponentially
    # - scheduler: "exponential"
    #   scheduler_params:
    #     gamma: 0.95
    
    # ReduceLROnPlateau: Reduce when metric plateaus
    # - scheduler: "plateau"
    #   scheduler_params:
    #     factor: 0.5
    #     patience: 10
    #     min_lr: 0.000001