{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2267af",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966c3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73914a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5109c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0069e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = pd.read_csv('/Users/baileyng/MIND_models/region_names/col_renames.csv')\n",
    "rename_dict = dict(zip(rename['datafield_code'], rename['datafield_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68392871",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/baileyng/MIND_models/region_names/MIND_avg_regions.txt', 'r') as f:\n",
    "    MIND_avg_regions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open('/Users/baileyng/MIND_models/region_names/MIND_regions.txt', 'r') as f:\n",
    "    MIND_regions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open('/Users/baileyng/MIND_models/region_names/CT_regions.txt', 'r') as f:\n",
    "    CT_regions_base = [line.strip() for line in f.readlines()]\n",
    "    CT_regions = [rename_dict[region] for region in CT_regions_base]\n",
    "\n",
    "with open('/Users/baileyng/MIND_models/region_names/FC_regions.txt', 'r') as f:\n",
    "    FC_regions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "demo = []\n",
    "\n",
    "# regions = [MIND_avg_regions, MIND_regions, CT_regions, FC_regions, demo]\n",
    "# region_names = ['MIND_avg_regions', 'MIND_regions', 'CT_regions', 'FC_regions', 'demo']\n",
    "regions = [MIND_avg_regions, CT_regions, FC_regions, demo]\n",
    "region_names = ['MIND_avg_regions', 'CT_regions', 'FC_regions', 'demo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4938fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables = ['age']\n",
    "\n",
    "categorical_variables = ['assessment_centre']\n",
    "\n",
    "binary_variables = ['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5cd407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_metrics(hyperparameter_dir, categorical_variables, binary_variables, numerical_variables):\n",
    "    all_results = {}\n",
    "\n",
    "    for i, region_name in enumerate(region_names):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Running analysis for: {region_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Create a local copy for this iteration\n",
    "        numerical_variables_copy = numerical_variables.copy()\n",
    "        numerical_variables_copy = numerical_variables_copy + regions[i]\n",
    "\n",
    "        if region_name == 'FC_regions':\n",
    "            numerical_variables_copy = numerical_variables_copy + ['head_motion']\n",
    "\n",
    "        region_hyperparameter_dir = os.path.join(hyperparameter_dir, region_name)\n",
    "        \n",
    "        # Check if the directory exists before running\n",
    "        if not os.path.exists(region_hyperparameter_dir):\n",
    "            print(f\"Directory not found: {region_hyperparameter_dir}\")\n",
    "            continue\n",
    "            \n",
    "        mae_list, rmse_list, r2_list = [], [], []\n",
    "\n",
    "        for split_idx in range(n_splits):\n",
    "            split_dir = os.path.join(region_hyperparameter_dir, f'split_{split_idx}')\n",
    "\n",
    "            # load data\n",
    "            data = np.load(os.path.join(split_dir, 'train_test_data.npz'), allow_pickle=True)\n",
    "            cols     = data['column_names']\n",
    "            X_train  = pd.DataFrame(data=data['x_train'], columns=cols)\n",
    "            X_test   = pd.DataFrame(data=data['x_test'],  columns=cols)\n",
    "            y_train  = data['y_train']\n",
    "            y_test   = data['y_test']\n",
    "\n",
    "            # cast types\n",
    "            for c in categorical_variables:\n",
    "                if c in cols:\n",
    "                    X_train[c] = X_train[c].astype('category')\n",
    "                    X_test[c]  = X_test[c].astype('category')\n",
    "            for b in binary_variables:\n",
    "                if b in cols:\n",
    "                    X_train[b] = pd.to_numeric(X_train[b], errors='coerce')\n",
    "                    X_test[b]  = pd.to_numeric(X_test[b], errors='coerce')\n",
    "\n",
    "            # load best hyperparams\n",
    "            with open(os.path.join(split_dir, 'best_hyperparameters.json'), 'r') as f:\n",
    "                params = json.load(f)\n",
    "\n",
    "            # choose objective/metric\n",
    "            if np.unique(y_train).shape[0] >= 3:\n",
    "                params.update({'eval_metric':'rmse', 'objective':'reg:squarederror'})\n",
    "            else:\n",
    "                params.update({'eval_metric':'auc',  'objective':'binary:logistic'})\n",
    "\n",
    "            # extract and remove n_estimators\n",
    "            n_estimators = int(params.pop('n_estimators'))\n",
    "\n",
    "            # scale numerics\n",
    "            scaler = StandardScaler()\n",
    "            num_vars = [v for v in cols if v in numerical_variables_copy]\n",
    "            if num_vars:\n",
    "                X_train[num_vars] = scaler.fit_transform(X_train[num_vars])\n",
    "                X_test[num_vars]  = scaler.transform(X_test[num_vars])\n",
    "\n",
    "            # train XGBoost\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical=True)\n",
    "            booster = xgb.train(params, dtrain, num_boost_round=n_estimators)\n",
    "\n",
    "            # predict\n",
    "            dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "            preds = booster.predict(dtest)\n",
    "\n",
    "            # compute metrics\n",
    "            mae  = mean_absolute_error(y_test, preds)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "            r2   = r2_score(y_test, preds)\n",
    "            # r2 = r2_score(y_test, preds, force_finite=False)\n",
    "\n",
    "            mae_list.append(mae)\n",
    "            rmse_list.append(rmse)\n",
    "            r2_list.append(r2)\n",
    "\n",
    "            print(f\"Split {split_idx:02d} → MAE: {mae:.3f}, RMSE: {rmse:.3f}, R²: {r2:.3f}\")\n",
    "\n",
    "        # after all splits, summary for this region\n",
    "        print(f\"\\nOverall performance for {region_name}:\")\n",
    "        print(f\"MAE  : {np.mean(mae_list):.3f} ± {np.std(mae_list):.3f}\")\n",
    "        print(f\"RMSE : {np.mean(rmse_list):.3f} ± {np.std(rmse_list):.3f}\")\n",
    "        print(f\"R²   : {np.mean(r2_list):.3f} ± {np.std(r2_list):.3f}\")\n",
    "        \n",
    "        # Store results for this region\n",
    "        all_results[region_name] = {\n",
    "            'mae_list': mae_list,\n",
    "            'rmse_list': rmse_list,\n",
    "            'r2_list': r2_list,\n",
    "            'mae_mean': np.mean(mae_list),\n",
    "            'mae_std': np.std(mae_list),\n",
    "            'rmse_mean': np.mean(rmse_list),\n",
    "            'rmse_std': np.std(rmse_list),\n",
    "            'r2_mean': np.mean(r2_list),\n",
    "            'r2_std': np.std(r2_list)\n",
    "        }\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12036f42",
   "metadata": {},
   "source": [
    "# GF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009f345e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running analysis for: MIND_avg_regions\n",
      "============================================================\n",
      "Split 00 → MAE: 1.711, RMSE: 2.143, R²: -0.092\n",
      "Split 01 → MAE: 1.621, RMSE: 2.008, R²: 0.045\n",
      "Split 02 → MAE: 1.634, RMSE: 2.038, R²: 0.028\n",
      "Split 03 → MAE: 1.741, RMSE: 2.168, R²: -0.109\n",
      "Split 04 → MAE: 1.683, RMSE: 2.099, R²: -0.038\n",
      "Split 05 → MAE: 1.721, RMSE: 2.141, R²: -0.057\n",
      "Split 06 → MAE: 1.725, RMSE: 2.157, R²: -0.111\n",
      "Split 07 → MAE: 1.568, RMSE: 1.971, R²: 0.033\n",
      "Split 08 → MAE: 1.635, RMSE: 2.051, R²: -0.002\n",
      "Split 09 → MAE: 1.588, RMSE: 1.993, R²: 0.040\n",
      "\n",
      "Overall performance for MIND_avg_regions:\n",
      "MAE  : 1.663 ± 0.058\n",
      "RMSE : 2.077 ± 0.070\n",
      "R²   : -0.026 ± 0.060\n",
      "\n",
      "============================================================\n",
      "Running analysis for: CT_regions\n",
      "============================================================\n",
      "Split 00 → MAE: 2.255, RMSE: 2.816, R²: -0.887\n",
      "Split 01 → MAE: 1.649, RMSE: 2.042, R²: 0.012\n",
      "Split 02 → MAE: 1.949, RMSE: 2.443, R²: -0.396\n",
      "Split 03 → MAE: 1.688, RMSE: 2.106, R²: -0.047\n",
      "Split 04 → MAE: 2.145, RMSE: 2.691, R²: -0.705\n",
      "Split 05 → MAE: 1.769, RMSE: 2.206, R²: -0.122\n",
      "Split 06 → MAE: 1.622, RMSE: 2.025, R²: 0.021\n",
      "Split 07 → MAE: 1.651, RMSE: 2.066, R²: -0.063\n",
      "Split 08 → MAE: 1.614, RMSE: 2.024, R²: 0.024\n",
      "Split 09 → MAE: 1.662, RMSE: 2.087, R²: -0.053\n",
      "\n",
      "Overall performance for CT_regions:\n",
      "MAE  : 1.800 ± 0.222\n",
      "RMSE : 2.251 ± 0.279\n",
      "R²   : -0.222 ± 0.312\n",
      "\n",
      "============================================================\n",
      "Running analysis for: FC_regions\n",
      "============================================================\n",
      "Split 00 → MAE: 1.661, RMSE: 2.084, R²: -0.033\n",
      "Split 01 → MAE: 1.737, RMSE: 2.157, R²: -0.102\n",
      "Split 02 → MAE: 1.602, RMSE: 2.008, R²: 0.057\n",
      "Split 03 → MAE: 1.606, RMSE: 2.006, R²: 0.051\n",
      "Split 04 → MAE: 1.675, RMSE: 2.086, R²: -0.025\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m hyperparameter_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/baileyng/MIND_data/hyperparameters/best_hyperparameters_20016-2.0_reg_07-21\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinary_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumerical_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumerical_variables\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 68\u001b[0m, in \u001b[0;36mtrain_test_metrics\u001b[0;34m(hyperparameter_dir, categorical_variables, binary_variables, numerical_variables)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# train XGBoost\u001b[39;00m\n\u001b[1;32m     67\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_train, label\u001b[38;5;241m=\u001b[39my_train, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 68\u001b[0m booster \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# predict\u001b[39;00m\n\u001b[1;32m     71\u001b[0m dtest \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test, label\u001b[38;5;241m=\u001b[39my_test, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/MIND_models/venv/lib/python3.8/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MIND_models/venv/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/MIND_models/venv/lib/python3.8/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparameter_dir = '/Users/baileyng/MIND_data/hyperparameters/best_hyperparameters_20016-2.0_reg_07-21'\n",
    "\n",
    "results = train_test_metrics(\n",
    "    hyperparameter_dir=hyperparameter_dir,\n",
    "    categorical_variables=categorical_variables,\n",
    "    binary_variables=binary_variables,\n",
    "    numerical_variables=numerical_variables\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
